{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from Bio import SeqIO\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../models/')\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, CSVLogger\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input,Conv1D, Dense,LSTM, MaxPooling1D, Flatten, Dropout, BatchNormalization, Activation,AveragePooling1D\n",
    "from tensorflow.keras import *\n",
    "#from group_norm import GroupNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2 ,l1\n",
    "import keras\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "import keras.backend as K\n",
    "from random import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from tcn import TCN\n",
    "\n",
    "\n",
    "#from  pyfasta import Fasta\n",
    "import gzip\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "#from data_gen import  DataGenerator_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import tensorflow as tf\n",
    "print(\"Num of GPUs available: \", len(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## END ##############################                    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enh_pos_seq = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Enhancer-chr1-pos-TRAIN.txt', \"fasta\"):\n",
    "    enh_pos_seq.append(str(seq_record.seq))\n",
    "enh_neg_seq = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Enhancer-chr1-neg-TRAIN.txt', \"fasta\"):\n",
    "    enh_neg_seq.append(str(seq_record.seq))\n",
    "enh_combine_seqs = enh_pos_seq + enh_neg_seq\n",
    "    \n",
    "############################################################################################################\n",
    "\n",
    "pro_pos_seq = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Promoter-chr1-pos-TRAIN.txt', \"fasta\"):\n",
    "    pro_pos_seq.append(str(seq_record.seq))\n",
    "pro_neg_seq = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Promoter-chr1-neg-TRAIN.txt', \"fasta\"):\n",
    "    pro_neg_seq.append(str(seq_record.seq))\n",
    "pro_combine_seqs = pro_pos_seq + pro_neg_seq\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "import re\n",
    "def get_feature(all_seqs,patterns):\n",
    "    all_feat = []\n",
    "    for seq in all_seqs:\n",
    "        feat= np.zeros((1,len(patterns)))\n",
    "        ix=0\n",
    "        for ix, pattern in enumerate(patterns):\n",
    "            pat='(?='+pattern+')'\n",
    "            featcnt=len(re.findall(pat,seq))\n",
    "            feat[0,ix] = featcnt\n",
    "            ix+=1\n",
    "        all_feat.append(feat)\n",
    "    return np.asarray(all_feat)\n",
    "\n",
    "patterns=['AAAAA','AAAAC','AAAAG','AAAAT','AAACA','AAACC','AAACG','AAACT','AAAGA','AAAGC','AAAGG','AAAGT','AAATA','AAATC','AAATG','AAATT','AACAA','AACAC','AACAG','AACAT','AACCA','AACCC','AACCG','AACCT','AACGA','AACGC','AACGG','AACGT','AACTA','AACTC','AACTG','AACTT','AAGAA','AAGAC','AAGAG','AAGAT','AAGCA','AAGCC','AAGCG','AAGCT','AAGGA','AAGGC','AAGGG','AAGGT','AAGTA','AAGTC','AAGTG','AAGTT','AATAA','AATAC','AATAG','AATAT','AATCA','AATCC','AATCG','AATCT','AATGA','AATGC','AATGG','AATGT','AATTA','AATTC','AATTG','AATTT','ACAAA','ACAAC','ACAAG','ACAAT','ACACA','ACACC','ACACG','ACACT','ACAGA','ACAGC','ACAGG','ACAGT','ACATA','ACATC','ACATG','ACATT','ACCAA','ACCAC','ACCAG','ACCAT','ACCCA','ACCCC','ACCCG','ACCCT','ACCGA','ACCGC','ACCGG','ACCGT','ACCTA','ACCTC','ACCTG','ACCTT','ACGAA','ACGAC','ACGAG','ACGAT','ACGCA','ACGCC','ACGCG','ACGCT','ACGGA','ACGGC','ACGGG','ACGGT','ACGTA','ACGTC','ACGTG','ACGTT','ACTAA','ACTAC','ACTAG','ACTAT','ACTCA','ACTCC','ACTCG','ACTCT','ACTGA','ACTGC','ACTGG','ACTGT','ACTTA','ACTTC','ACTTG','ACTTT','AGAAA','AGAAC','AGAAG','AGAAT','AGACA','AGACC','AGACG','AGACT','AGAGA','AGAGC','AGAGG','AGAGT','AGATA','AGATC','AGATG','AGATT','AGCAA','AGCAC','AGCAG','AGCAT','AGCCA','AGCCC','AGCCG','AGCCT','AGCGA','AGCGC','AGCGG','AGCGT','AGCTA','AGCTC','AGCTG','AGCTT','AGGAA','AGGAC','AGGAG','AGGAT','AGGCA','AGGCC','AGGCG','AGGCT','AGGGA','AGGGC','AGGGG','AGGGT','AGGTA','AGGTC','AGGTG','AGGTT','AGTAA','AGTAC','AGTAG','AGTAT','AGTCA','AGTCC','AGTCG','AGTCT','AGTGA','AGTGC','AGTGG','AGTGT','AGTTA','AGTTC','AGTTG','AGTTT','ATAAA','ATAAC','ATAAG','ATAAT','ATACA','ATACC','ATACG','ATACT','ATAGA','ATAGC','ATAGG','ATAGT','ATATA','ATATC','ATATG','ATATT','ATCAA','ATCAC','ATCAG','ATCAT','ATCCA','ATCCC','ATCCG','ATCCT','ATCGA','ATCGC','ATCGG','ATCGT','ATCTA','ATCTC','ATCTG','ATCTT','ATGAA','ATGAC','ATGAG','ATGAT','ATGCA','ATGCC','ATGCG','ATGCT','ATGGA','ATGGC','ATGGG','ATGGT','ATGTA','ATGTC','ATGTG','ATGTT','ATTAA','ATTAC','ATTAG','ATTAT','ATTCA','ATTCC','ATTCG','ATTCT','ATTGA','ATTGC','ATTGG','ATTGT','ATTTA','ATTTC','ATTTG','ATTTT','CAAAA','CAAAC','CAAAG','CAAAT','CAACA','CAACC','CAACG','CAACT','CAAGA','CAAGC','CAAGG','CAAGT','CAATA','CAATC','CAATG','CAATT','CACAA','CACAC','CACAG','CACAT','CACCA','CACCC','CACCG','CACCT','CACGA','CACGC','CACGG','CACGT','CACTA','CACTC','CACTG','CACTT','CAGAA','CAGAC','CAGAG','CAGAT','CAGCA','CAGCC','CAGCG','CAGCT','CAGGA','CAGGC','CAGGG','CAGGT','CAGTA','CAGTC','CAGTG','CAGTT','CATAA','CATAC','CATAG','CATAT','CATCA','CATCC','CATCG','CATCT','CATGA','CATGC','CATGG','CATGT','CATTA','CATTC','CATTG','CATTT','CCAAA','CCAAC','CCAAG','CCAAT','CCACA','CCACC','CCACG','CCACT','CCAGA','CCAGC','CCAGG','CCAGT','CCATA','CCATC','CCATG','CCATT','CCCAA','CCCAC','CCCAG','CCCAT','CCCCA','CCCCC','CCCCG','CCCCT','CCCGA','CCCGC','CCCGG','CCCGT','CCCTA','CCCTC','CCCTG','CCCTT','CCGAA','CCGAC','CCGAG','CCGAT','CCGCA','CCGCC','CCGCG','CCGCT','CCGGA','CCGGC','CCGGG','CCGGT','CCGTA','CCGTC','CCGTG','CCGTT','CCTAA','CCTAC','CCTAG','CCTAT','CCTCA','CCTCC','CCTCG','CCTCT','CCTGA','CCTGC','CCTGG','CCTGT','CCTTA','CCTTC','CCTTG','CCTTT','CGAAA','CGAAC','CGAAG','CGAAT','CGACA','CGACC','CGACG','CGACT','CGAGA','CGAGC','CGAGG','CGAGT','CGATA','CGATC','CGATG','CGATT','CGCAA','CGCAC','CGCAG','CGCAT','CGCCA','CGCCC','CGCCG','CGCCT','CGCGA','CGCGC','CGCGG','CGCGT','CGCTA','CGCTC','CGCTG','CGCTT','CGGAA','CGGAC','CGGAG','CGGAT','CGGCA','CGGCC','CGGCG','CGGCT','CGGGA','CGGGC','CGGGG','CGGGT','CGGTA','CGGTC','CGGTG','CGGTT','CGTAA','CGTAC','CGTAG','CGTAT','CGTCA','CGTCC','CGTCG','CGTCT','CGTGA','CGTGC','CGTGG','CGTGT','CGTTA','CGTTC','CGTTG','CGTTT','CTAAA','CTAAC','CTAAG','CTAAT','CTACA','CTACC','CTACG','CTACT','CTAGA','CTAGC','CTAGG','CTAGT','CTATA','CTATC','CTATG','CTATT','CTCAA','CTCAC','CTCAG','CTCAT','CTCCA','CTCCC','CTCCG','CTCCT','CTCGA','CTCGC','CTCGG','CTCGT','CTCTA','CTCTC','CTCTG','CTCTT','CTGAA','CTGAC','CTGAG','CTGAT','CTGCA','CTGCC','CTGCG','CTGCT','CTGGA','CTGGC','CTGGG','CTGGT','CTGTA','CTGTC','CTGTG','CTGTT','CTTAA','CTTAC','CTTAG','CTTAT','CTTCA','CTTCC','CTTCG','CTTCT','CTTGA','CTTGC','CTTGG','CTTGT','CTTTA','CTTTC','CTTTG','CTTTT','GAAAA','GAAAC','GAAAG','GAAAT','GAACA','GAACC','GAACG','GAACT','GAAGA','GAAGC','GAAGG','GAAGT','GAATA','GAATC','GAATG','GAATT','GACAA','GACAC','GACAG','GACAT','GACCA','GACCC','GACCG','GACCT','GACGA','GACGC','GACGG','GACGT','GACTA','GACTC','GACTG','GACTT','GAGAA','GAGAC','GAGAG','GAGAT','GAGCA','GAGCC','GAGCG','GAGCT','GAGGA','GAGGC','GAGGG','GAGGT','GAGTA','GAGTC','GAGTG','GAGTT','GATAA','GATAC','GATAG','GATAT','GATCA','GATCC','GATCG','GATCT','GATGA','GATGC','GATGG','GATGT','GATTA','GATTC','GATTG','GATTT','GCAAA','GCAAC','GCAAG','GCAAT','GCACA','GCACC','GCACG','GCACT','GCAGA','GCAGC','GCAGG','GCAGT','GCATA','GCATC','GCATG','GCATT','GCCAA','GCCAC','GCCAG','GCCAT','GCCCA','GCCCC','GCCCG','GCCCT','GCCGA','GCCGC','GCCGG','GCCGT','GCCTA','GCCTC','GCCTG','GCCTT','GCGAA','GCGAC','GCGAG','GCGAT','GCGCA','GCGCC','GCGCG','GCGCT','GCGGA','GCGGC','GCGGG','GCGGT','GCGTA','GCGTC','GCGTG','GCGTT','GCTAA','GCTAC','GCTAG','GCTAT','GCTCA','GCTCC','GCTCG','GCTCT','GCTGA','GCTGC','GCTGG','GCTGT','GCTTA','GCTTC','GCTTG','GCTTT','GGAAA','GGAAC','GGAAG','GGAAT','GGACA','GGACC','GGACG','GGACT','GGAGA','GGAGC','GGAGG','GGAGT','GGATA','GGATC','GGATG','GGATT','GGCAA','GGCAC','GGCAG','GGCAT','GGCCA','GGCCC','GGCCG','GGCCT','GGCGA','GGCGC','GGCGG','GGCGT','GGCTA','GGCTC','GGCTG','GGCTT','GGGAA','GGGAC','GGGAG','GGGAT','GGGCA','GGGCC','GGGCG','GGGCT','GGGGA','GGGGC','GGGGG','GGGGT','GGGTA','GGGTC','GGGTG','GGGTT','GGTAA','GGTAC','GGTAG','GGTAT','GGTCA','GGTCC','GGTCG','GGTCT','GGTGA','GGTGC','GGTGG','GGTGT','GGTTA','GGTTC','GGTTG','GGTTT','GTAAA','GTAAC','GTAAG','GTAAT','GTACA','GTACC','GTACG','GTACT','GTAGA','GTAGC','GTAGG','GTAGT','GTATA','GTATC','GTATG','GTATT','GTCAA','GTCAC','GTCAG','GTCAT','GTCCA','GTCCC','GTCCG','GTCCT','GTCGA','GTCGC','GTCGG','GTCGT','GTCTA','GTCTC','GTCTG','GTCTT','GTGAA','GTGAC','GTGAG','GTGAT','GTGCA','GTGCC','GTGCG','GTGCT','GTGGA','GTGGC','GTGGG','GTGGT','GTGTA','GTGTC','GTGTG','GTGTT','GTTAA','GTTAC','GTTAG','GTTAT','GTTCA','GTTCC','GTTCG','GTTCT','GTTGA','GTTGC','GTTGG','GTTGT','GTTTA','GTTTC','GTTTG','GTTTT','TAAAA','TAAAC','TAAAG','TAAAT','TAACA','TAACC','TAACG','TAACT','TAAGA','TAAGC','TAAGG','TAAGT','TAATA','TAATC','TAATG','TAATT','TACAA','TACAC','TACAG','TACAT','TACCA','TACCC','TACCG','TACCT','TACGA','TACGC','TACGG','TACGT','TACTA','TACTC','TACTG','TACTT','TAGAA','TAGAC','TAGAG','TAGAT','TAGCA','TAGCC','TAGCG','TAGCT','TAGGA','TAGGC','TAGGG','TAGGT','TAGTA','TAGTC','TAGTG','TAGTT','TATAA','TATAC','TATAG','TATAT','TATCA','TATCC','TATCG','TATCT','TATGA','TATGC','TATGG','TATGT','TATTA','TATTC','TATTG','TATTT','TCAAA','TCAAC','TCAAG','TCAAT','TCACA','TCACC','TCACG','TCACT','TCAGA','TCAGC','TCAGG','TCAGT','TCATA','TCATC','TCATG','TCATT','TCCAA','TCCAC','TCCAG','TCCAT','TCCCA','TCCCC','TCCCG','TCCCT','TCCGA','TCCGC','TCCGG','TCCGT','TCCTA','TCCTC','TCCTG','TCCTT','TCGAA','TCGAC','TCGAG','TCGAT','TCGCA','TCGCC','TCGCG','TCGCT','TCGGA','TCGGC','TCGGG','TCGGT','TCGTA','TCGTC','TCGTG','TCGTT','TCTAA','TCTAC','TCTAG','TCTAT','TCTCA','TCTCC','TCTCG','TCTCT','TCTGA','TCTGC','TCTGG','TCTGT','TCTTA','TCTTC','TCTTG','TCTTT','TGAAA','TGAAC','TGAAG','TGAAT','TGACA','TGACC','TGACG','TGACT','TGAGA','TGAGC','TGAGG','TGAGT','TGATA','TGATC','TGATG','TGATT','TGCAA','TGCAC','TGCAG','TGCAT','TGCCA','TGCCC','TGCCG','TGCCT','TGCGA','TGCGC','TGCGG','TGCGT','TGCTA','TGCTC','TGCTG','TGCTT','TGGAA','TGGAC','TGGAG','TGGAT','TGGCA','TGGCC','TGGCG','TGGCT','TGGGA','TGGGC','TGGGG','TGGGT','TGGTA','TGGTC','TGGTG','TGGTT','TGTAA','TGTAC','TGTAG','TGTAT','TGTCA','TGTCC','TGTCG','TGTCT','TGTGA','TGTGC','TGTGG','TGTGT','TGTTA','TGTTC','TGTTG','TGTTT','TTAAA','TTAAC','TTAAG','TTAAT','TTACA','TTACC','TTACG','TTACT','TTAGA','TTAGC','TTAGG','TTAGT','TTATA','TTATC','TTATG','TTATT','TTCAA','TTCAC','TTCAG','TTCAT','TTCCA','TTCCC','TTCCG','TTCCT','TTCGA','TTCGC','TTCGG','TTCGT','TTCTA','TTCTC','TTCTG','TTCTT','TTGAA','TTGAC','TTGAG','TTGAT','TTGCA','TTGCC','TTGCG','TTGCT','TTGGA','TTGGC','TTGGG','TTGGT','TTGTA','TTGTC','TTGTG','TTGTT','TTTAA','TTTAC','TTTAG','TTTAT','TTTCA','TTTCC','TTTCG','TTTCT','TTTGA','TTTGC','TTTGG','TTTGT','TTTTA','TTTTC','TTTTG','TTTTT']\n",
    "\n",
    "############################################################################################################\n",
    "enh_kmer_feature=get_feature(enh_combine_seqs,patterns)\n",
    "pro_kmer_feature=get_feature(pro_combine_seqs,patterns)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "pro_kmer_feature.shape\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_kmer_feature=enh_kmer_feature/3000.        #Normalize the patteren from 0 to 1..... 41 reprsents the length of sequecne\n",
    "pro_kmer_feature=pro_kmer_feature/2000.        #Normalize the patteren from 0 to 1..... 41 reprsents the length of sequecne\n",
    "############################################################################################################\n",
    "\n",
    "bases = ['A','C','G','T']\n",
    "def onehot(seq):\n",
    "    X = np.zeros((len(seq),len(seq[0]), len(bases)))\n",
    "    print(len(seq),len(seq[0]), len(bases))\n",
    "    for l,s in enumerate(seq):\n",
    "        for i, char in enumerate(s):\n",
    "            if char in bases:\n",
    "                X[l,i, bases.index(char)] = 1\n",
    "    return X\n",
    "def shuffle_ab(a,b,c,d,e):\n",
    "    s = np.arange(a.shape[0])\n",
    "    shuffle(s)\n",
    "    return a[s],b[s],c[s],d[s],e[s]\n",
    "\n",
    "############################################################################################################\n",
    "from sklearn.utils import compute_class_weight\n",
    "lbs = list(np.ones(len(enh_pos_seq))) + list(np.zeros(len(enh_neg_seq)))\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(lbs),\n",
    "                                        y = lbs                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(lbs), class_weights))\n",
    "class_weights\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "p=list(np.zeros(len(enh_pos_seq))) \n",
    "print(len(p))\n",
    "\n",
    "############################################################################################################\n",
    "enh_features = onehot(enh_combine_seqs)\n",
    "enh_features=np.asarray(enh_features,dtype=np.float)\n",
    "enh_features.shape\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "pro_features = onehot(pro_combine_seqs)\n",
    "pro_features=np.asarray(pro_features,dtype=np.float)\n",
    "pro_features.shape\n",
    "\n",
    "############################################################################################################\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder() \n",
    "lbs = np.array(lbs).reshape(-1, 1)\n",
    "Input_labels = one_hot_encoder.fit_transform(lbs).toarray()\n",
    "Input_labels = np.array(lbs)\n",
    "Input_labels.shape\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_features,pro_features,enh_kmer,pro_kmer,Input_labels=shuffle_ab(enh_features,pro_features,enh_kmer_feature,pro_kmer_feature,Input_labels)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "class CustomModelCheckpoint(keras.callbacks.Callback):\n",
    "    def __init__(self, model, path):\n",
    "        self.path = path\n",
    "        self.model_for_saving = model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs['val_loss']\n",
    "        print(\"\\nSaving model to : {}\".format(self.path.format(epoch=epoch, val_loss=loss)))\n",
    "        self.model_for_saving.save_weights(self.path.format(epoch=epoch, val_loss=loss), overwrite=True)\n",
    "def step_decay(epoch):\n",
    "    lrate=[0.001]*30+[0.0001]*170\n",
    "    print (lrate[epoch])\n",
    "    return lrate[epoch]\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "model_name= 'EPI'\n",
    "result_folder= 'GM12878_FOLD_TEST-TRAN_LeftOut_chr1/results/'\n",
    "if not os.path.exists(result_folder+model_name):\n",
    "    os.makedirs(result_folder+model_name)\n",
    "\n",
    "model_results_folder=result_folder+model_name+ '/'\n",
    "best_weights = model_results_folder + 'best_weights.h5'\n",
    "last_weights = model_results_folder + 'last_weights.h5'\n",
    "model_arch = model_results_folder + 'model.jsno'\n",
    "history_pth = model_results_folder + 'results.pickle'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_inp1=Input((3000,4))\n",
    "enh_inp2 = Input((1,1024))\n",
    "pro_inp1=Input((2000,4))\n",
    "pro_inp2 = Input((1,1024))\n",
    "\n",
    "enh_x1= Conv1D(16,13,strides=2,padding='same',activation = 'relu',kernel_regularizer = regularizers.l2(1e-3),bias_regularizer = regularizers.l2(1e-4),kernel_initializer='random_normal')(enh_inp1)\n",
    "enh_x1= Conv1D(32,23,strides=2,padding='same',activation = 'relu',kernel_regularizer = regularizers.l2(1e-3),bias_regularizer = regularizers.l2(1e-4),kernel_initializer='random_normal')(enh_x1)\n",
    "enh_x1= MaxPooling1D(pool_size = 40,strides=20)(enh_x1)\n",
    "enh_x1 = Dropout(0.5)(enh_x1)\n",
    "enh_x1= Flatten()(enh_x1)\n",
    "enh_x2= Flatten()(enh_inp2)\n",
    "enh_x = concatenate([enh_x1,enh_x2], axis=1)\n",
    "enh_x = BatchNormalization()(enh_x)\n",
    "enh_x = Dropout(0.5)(enh_x)\n",
    "\n",
    "pro_x1= Conv1D(16,13,strides=2,padding='same',activation = 'relu',kernel_regularizer = regularizers.l2(1e-3),bias_regularizer = regularizers.l2(1e-4),kernel_initializer='random_normal')(pro_inp1)\n",
    "pro_x1= Conv1D(32,23,strides=2,padding='same',activation = 'relu',kernel_regularizer = regularizers.l2(1e-3),bias_regularizer = regularizers.l2(1e-4),kernel_initializer='random_normal')(pro_x1)\n",
    "pro_x1= MaxPooling1D(pool_size = 40,strides=20)(pro_x1)\n",
    "pro_x1 = Dropout(0.5)(pro_x1)\n",
    "pro_x1= Flatten()(pro_x1)\n",
    "pro_x2= Flatten()(pro_inp2)\n",
    "pro_x = concatenate([pro_x1,pro_x2], axis=1)\n",
    "pro_x = BatchNormalization()(pro_x)\n",
    "pro_x = Dropout(0.5)(pro_x)\n",
    "    \n",
    "x = concatenate([enh_x,pro_x], axis=1)\n",
    "x=BatchNormalization()(x)\n",
    "x= Flatten()(x)\n",
    "\n",
    "x = Dense(1,activation='sigmoid',kernel_regularizer=l2(0.001),kernel_initializer='he_uniform')(x)\n",
    "model= Model(inputs=[enh_inp1,enh_inp2,pro_inp1,pro_inp2],outputs=x)\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "if not os.path.exists(result_folder+model_name):\n",
    "    os.makedirs(result_folder+model_name)\n",
    "\n",
    "model_results_folder=result_folder+model_name+ '/'\n",
    "history_pth = model_results_folder + 'results.pickle'\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(model_results_folder+\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "checkpoint = ModelCheckpoint(best_weights, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "\n",
    "checkpointsString = model_results_folder + 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks = [lrate, CustomModelCheckpoint(model, checkpointsString),checkpoint]\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.002,amsgrad = True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "history = model.fit([enh_features,enh_kmer,pro_features,pro_kmer],Input_labels,class_weight=class_weights,batch_size=100,epochs=70,shuffle=True, validation_split=0.1,callbacks=callbacks)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "import pickle\n",
    "with open(history_pth, 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "model.load_weights(best_weights)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_ind_pos = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Enhancer-chr1-pos-TEST.txt', \"fasta\"):\n",
    "    enh_ind_pos.append(str(seq_record.seq))\n",
    "enh_ind_neg = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Enhancer-chr1-neg-TEST.txt', \"fasta\"):\n",
    "    enh_ind_neg.append(str(seq_record.seq))\n",
    "pro_ind_pos = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Promoter-chr1-pos-TEST.txt', \"fasta\"):\n",
    "    pro_ind_pos.append(str(seq_record.seq))\n",
    "pro_ind_neg = []\n",
    "for seq_record in SeqIO.parse('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/Promoter-chr1-neg-TEST.txt', \"fasta\"):\n",
    "    pro_ind_neg.append(str(seq_record.seq))\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_ind_comb = enh_ind_pos+enh_ind_neg\n",
    "pro_ind_comb = pro_ind_pos+pro_ind_neg\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_ind_features = onehot(enh_ind_comb)\n",
    "enh_ind_features=np.asarray(enh_ind_features,dtype=np.float)\n",
    "enh_ind_features.shape\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_kmer_ind=get_feature(enh_ind_comb,patterns)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "pro_ind_features = onehot(pro_ind_comb)\n",
    "pro_ind_features=np.asarray(pro_ind_features,dtype=np.float)\n",
    "pro_ind_features.shape\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "pro_kmer_ind=get_feature(pro_ind_comb,patterns)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_kmer_ind=enh_kmer_ind/3000.\n",
    "pro_kmer_ind=pro_kmer_ind/2000.\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "lbs = list(np.ones(len(enh_ind_pos))) + list(np.zeros(len(enh_ind_neg)))\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder() \n",
    "lbs = np.array(lbs).reshape(-1, 1)\n",
    "Input_labels = one_hot_encoder.fit_transform(lbs).toarray()\n",
    "Input_labels = np.array(lbs)\n",
    "Input_labels.shape\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "np.save('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/enh_ind_test',enh_ind_features)\n",
    "np.save('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/enh_ind_kmer',enh_kmer_ind)\n",
    "np.save('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/pro_folds/pro_ind_test',pro_ind_features)\n",
    "np.save('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/pro_folds/pro_ind_kmer',pro_kmer_ind)\n",
    "np.save('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/ind_y_test',Input_labels)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "enh_ind_test,pro_ind_test,test_labels=np.load('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/enh_ind_test.npy'),np.load('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/pro_folds/pro_ind_test.npy'), np.load('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/ind_y_test.npy')\n",
    "enh_kmer_ind, pro_kmer_ind = np.load('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/enh_folds/enh_ind_kmer.npy'),np.load('GM12878_FOLD_TEST-TRAN_LeftOut_chr1/pro_folds/pro_ind_kmer.npy')\n",
    "y_scores= model.predict([enh_ind_test,enh_kmer_ind,pro_ind_test,pro_kmer_ind])\n",
    "y_true=test_labels\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "#scikit learn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#Area under the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve((y_true), y_scores)\n",
    "AUC_ROC = roc_auc_score(y_true, y_scores)\n",
    "# test_integral = np.trapz(tpr,fpr) #trapz is numpy integration\n",
    "print (\"\\nArea under the ROC curve: \" +str(AUC_ROC))\n",
    "roc_curve =plt.figure()\n",
    "plt.plot(fpr,tpr,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel(\"FPR (False Positive Rate)\")\n",
    "plt.ylabel(\"TPR (True Positive Rate)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(path_experiment+\"ROC.png\")\n",
    "plt.savefig('EPI-ROC.png')\n",
    "#Precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "precision = np.fliplr([precision])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "recall = np.fliplr([recall])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "AUC_prec_rec = np.trapz(precision,recall)\n",
    "print (\"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec))\n",
    "prec_rec_curve = plt.figure()\n",
    "plt.plot(recall,precision,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n",
    "plt.title('Precision - Recall curve')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(path_experiment+\"Precision_recall.png\")\n",
    "\n",
    "#Confusion matrix\n",
    "threshold_confusion = 0.5\n",
    "#print (\"\\nConfusion matrix:  Custom threshold (for positive) of \" +str(threshold_confusion))\n",
    "y_pred = np.empty((y_scores.shape[0]))\n",
    "for i in range(y_scores.shape[0]):\n",
    "    if y_scores[i]>=threshold_confusion:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "#print (confusion)\n",
    "accuracy = 0\n",
    "if float(np.sum(confusion))!=0:\n",
    "    accuracy = float(confusion[0,0]+confusion[1,1])/float(np.sum(confusion))\n",
    "#print (\"Global Accuracy: \" +str(accuracy))\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "#print (\"Specificity: \" +str(specificity))\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "#print (\"Sensitivity: \" +str(sensitivity))\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "#print (\"Precision: \" +str(precision))\n",
    "\n",
    "#Jaccard similarity index\n",
    "#jaccard_index = jaccard_similarity_score(y_true, y_pred, normalize=True)\n",
    "#print (\"\\nJaccard similarity score: \" +str(jaccard_index))\n",
    "\n",
    "#F1 score\n",
    "F1_score = f1_score(y_true, y_pred, labels=None, average='binary', sample_weight=None)\n",
    "print (\"\\nF1 score (F-measure): \" +str(F1_score))\n",
    "\n",
    "mcc= matthews_corrcoef(y_true, y_pred)\n",
    "#print ('MCC:', mcc)\n",
    "\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
